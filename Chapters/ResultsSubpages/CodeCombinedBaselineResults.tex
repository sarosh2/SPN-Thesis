\begin{table}[H]
\centering
\caption{Benchmarks and Task-specific evaluation results for Baseline runs of Code Generation use case}
\begin{tabular}{|c|l|l|l|l|l|l|}
\hline
\multicolumn{1}{|l|}{\textbf{Evaluation}}  & \textbf{Dataset} & \textbf{N} & \textbf{pre\_eval} & \textbf{post\_eval1} & \textbf{post\_eval2} & \textbf{post\_eval3} \\ \hline
\multirow{3}{*}{HumanEval   (+ MultiPL-E)} & C++              & 80         & 0.6375             & 0.4583               & 0.4854               & 0.4313               \\ \cline{2-7} 
                                           & Java             & 80         & 0.6438             & 0.5354               & 0.4427               & 0.3833               \\ \cline{2-7} 
                                           & Python           & 80         & 0.7688             & 0.6958               & 0.6094               & 0.6448               \\ \hline
CoNaLa                                     & CoNaLa           & 100        & 0.2162             & 0.2178               & 0.2101               & 0.2027               \\ \hline
\multirow{2}{*}{cg}                        & Test             & 500        & 0.0463             & 0.0754               & 0.1137               & 0.1392               \\ \cline{2-7} 
                                           & Validation       & 501        & 0.0419             & 0.0766               & 0.1146               & 0.1379               \\ \hline
\multirow{2}{*}{utg}                       & Test             & 48         & 0.1143             & 0.1073               & 0.1133               & 0.1145               \\ \cline{2-7} 
                                           & Validation       & 48         & 0.1527             & 0.1508               & 0.1583               & 0.1658               \\ \hline
\multirow{2}{*}{mg}                        & Test             & 145        & 0.0349             & 0.0335               & 0.0463               & 0.0541               \\ \cline{2-7} 
                                           & Validation       & 146        & 0.0364             & 0.0295               & 0.0390               & 0.0444               \\ \hline
\end{tabular}
\label{tab:CodeBaselineCombined}
\end{table}


% \begin{table}[h!]
% \centering
% \caption{Benchmarks and Task-specific evaluation results for Baseline runs of Code Generation use case}
% \begin{tabular}{|l|l|r|r|r|r|}
% \hline
% Evaluation & Dataset & pre\_eval & post\_eval1 & post\_eval2 & post\_eval3 \\
% \hline
% \multirow{3}{*}{HumanEval (+ MultiPL-E)} & C++ & 0.6375 & 0.458333 & 0.485417 & 0.43125 \\
% \cline{2-6}
% & Java & 0.64375 & 0.535417 & 0.442708 & 0.383333 \\
% \cline{2-6}
% & Python & 0.76875 & 0.695833 & 0.609375 & 0.644792 \\
% \hline
% CoNaLa & CoNaLa & 0.216249 & 0.217774 & 0.210067 & 0.202716 \\
% \hline
% \multirow{2}{*}{cg} & Test & 0.046312 & 0.075411 & 0.113695 & 0.139169 \\
% \cline{2-6}
% & Validation & 0.041909 & 0.076567 & 0.114612 & 0.13788 \\
% \hline
% \multirow{2}{*}{utg} & Test & 0.114348 & 0.107345 & 0.113327 & 0.114511 \\
% \cline{2-6}
% & Validation & 0.152672 & 0.150773 & 0.158349 & 0.165846 \\
% \hline
% \multirow{2}{*}{mg} & Test & 0.034924 & 0.033462 & 0.046339 & 0.054133 \\
% \cline{2-6}
% & Validation & 0.03639 & 0.029505 & 0.039047 & 0.044422 \\
% \hline
% \end{tabular}
% \label{tab:CodeBaselineCombined}
% \end{table}